#!/usr/bin/env python3
"""
Script pour g√©n√©rer des donn√©es de test pour le tableau de bord NeuroScan Pro
"""

import sqlite3
import json
import random
from datetime import datetime, timedelta

DATABASE_PATH = 'neuroscan_analytics.db'

def generate_test_data():
    """G√©n√©rer des donn√©es de test pour la base de donn√©es"""
    
    # Donn√©es de test
    tumor_types = [
        {'class': 0, 'label': 'Normal'},
        {'class': 1, 'label': 'Gliome'},
        {'class': 2, 'label': 'M√©ningiome'},
        {'class': 3, 'label': 'Tumeur pituitaire'}
    ]
    
    filenames = [
        'brain_scan_001.jpg', 'mri_patient_002.png', 'irm_cerveau_003.jpg',
        'brain_tumor_004.png', 'scan_medical_005.jpg', 'patient_006_irm.png',
        'neurologie_007.jpg', 'brain_analysis_008.png', 'medical_scan_009.jpg',
        'irm_diagnostic_010.png', 'brain_study_011.jpg', 'neuro_scan_012.png'
    ]
    
    recommendations_templates = {
        'Normal': [
            "Aucune anomalie d√©tect√©e dans cette analyse",
            "Suivi de routine recommand√© selon les protocoles standards",
            "Consultation avec un radiologue pour confirmation"
        ],
        'Gliome': [
            "Biopsie recommand√©e pour confirmation histologique",
            "IRM de suivi dans 3 mois pour √©valuation de la croissance",
            "Consultation avec un neuro-oncologue sp√©cialis√©",
            "√âvaluation neuropsychologique recommand√©e"
        ],
        'M√©ningiome': [
            "Surveillance radiologique tous les 6 mois",
            "Consultation neurochirurgicale pour √©valuation",
            "IRM avec contraste pour meilleure caract√©risation",
            "√âvaluation des sympt√¥mes neurologiques"
        ],
        'Tumeur pituitaire': [
            "Bilan hormonal complet recommand√©",
            "Consultation endocrinologique urgente",
            "IRM hypophysaire avec coupes fines",
            "√âvaluation ophtalmologique (champ visuel)"
        ]
    }
    
    descriptions_templates = {
        'Normal': [
            "L'analyse r√©v√®le des structures c√©r√©brales normales sans anomalie d√©tectable.",
            "Aucune l√©sion suspecte identifi√©e sur cette imagerie c√©r√©brale.",
            "Les tissus c√©r√©braux pr√©sentent un aspect normal et homog√®ne."
        ],
        'Gliome': [
            "Pr√©sence d'une l√©sion compatible avec un gliome de grade ind√©termin√©.",
            "Masse tissulaire suspecte avec caract√©ristiques √©vocatrices d'un gliome.",
            "L√©sion infiltrante sugg√©rant un processus glial n√©oplasique."
        ],
        'M√©ningiome': [
            "L√©sion extra-axiale √©vocatrice d'un m√©ningiome bien d√©limit√©.",
            "Masse arrondie avec prise de contraste homog√®ne, typique d'un m√©ningiome.",
            "Formation tumorale b√©nigne compatible avec un m√©ningiome."
        ],
        'Tumeur pituitaire': [
            "Anomalie de la r√©gion sellaire √©vocatrice d'un ad√©nome hypophysaire.",
            "L√©sion de l'hypophyse avec extension suprasellaire possible.",
            "Masse hypophysaire n√©cessitant une √©valuation endocrinologique."
        ]
    }
    
    conn = sqlite3.connect(DATABASE_PATH)
    cursor = conn.cursor()
    
    # G√©n√©rer des analyses sur les 30 derniers jours
    base_date = datetime.now() - timedelta(days=30)
    
    print("G√©n√©ration de donn√©es de test...")
    
    for day in range(30):
        current_date = base_date + timedelta(days=day)
        
        # Nombre d'analyses par jour (entre 1 et 15)
        daily_analyses = random.randint(1, 15)
        
        for _ in range(daily_analyses):
            # Choisir un type de tumeur avec des probabilit√©s r√©alistes
            tumor_weights = [0.6, 0.15, 0.15, 0.1]  # Normal plus fr√©quent
            tumor_type = random.choices(tumor_types, weights=tumor_weights)[0]
            
            # G√©n√©rer des probabilit√©s r√©alistes
            probabilities = {}
            for t in tumor_types:
                if t['class'] == tumor_type['class']:
                    # Probabilit√© √©lev√©e pour la classe pr√©dite
                    probabilities[t['label']] = random.uniform(0.7, 0.95)
                else:
                    # Probabilit√©s faibles pour les autres classes
                    probabilities[t['label']] = random.uniform(0.01, 0.3)
            
            # Normaliser les probabilit√©s
            total = sum(probabilities.values())
            probabilities = {k: v/total for k, v in probabilities.items()}
            
            # Confidence = probabilit√© de la classe pr√©dite
            confidence = probabilities[tumor_type['label']]
            
            # Choisir des recommandations et description
            available_recs = recommendations_templates[tumor_type['label']]
            num_recs = min(random.randint(2, 4), len(available_recs))
            recommendations = random.sample(available_recs, num_recs)
            description = random.choice(descriptions_templates[tumor_type['label']])
            
            # G√©n√©rer un timestamp al√©atoire dans la journ√©e
            hour = random.randint(8, 18)  # Heures de travail
            minute = random.randint(0, 59)
            timestamp = current_date.replace(hour=hour, minute=minute)
            
            # Ins√©rer l'analyse
            cursor.execute('''
                INSERT INTO analyses 
                (timestamp, filename, predicted_class, predicted_label, confidence, 
                 probabilities, description, recommendations, processing_time, 
                 user_session, ip_address)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                timestamp.isoformat(),
                random.choice(filenames),
                tumor_type['class'],
                tumor_type['label'],
                confidence,
                json.dumps(probabilities),
                description,
                json.dumps(recommendations),
                random.uniform(2.5, 8.5),  # Temps de traitement
                f"session_{random.randint(1000, 9999)}",
                f"192.168.1.{random.randint(1, 254)}"
            ))
    
    # Mettre √† jour les statistiques quotidiennes
    print("Mise √† jour des statistiques quotidiennes...")
    
    cursor.execute('''
        INSERT OR REPLACE INTO daily_stats 
        (date, total_analyses, normal_count, gliome_count, meningiome_count, 
         pituitary_count, avg_confidence, avg_processing_time)
        SELECT 
            DATE(timestamp) as date,
            COUNT(*) as total_analyses,
            SUM(CASE WHEN predicted_label = 'Normal' THEN 1 ELSE 0 END) as normal_count,
            SUM(CASE WHEN predicted_label = 'Gliome' THEN 1 ELSE 0 END) as gliome_count,
            SUM(CASE WHEN predicted_label = 'M√©ningiome' THEN 1 ELSE 0 END) as meningiome_count,
            SUM(CASE WHEN predicted_label = 'Tumeur pituitaire' THEN 1 ELSE 0 END) as pituitary_count,
            AVG(confidence) as avg_confidence,
            AVG(processing_time) as avg_processing_time
        FROM analyses
        GROUP BY DATE(timestamp)
    ''')
    
    conn.commit()
    
    # Afficher les statistiques
    cursor.execute('SELECT COUNT(*) FROM analyses')
    total_analyses = cursor.fetchone()[0]
    
    cursor.execute('SELECT predicted_label, COUNT(*) FROM analyses GROUP BY predicted_label')
    distribution = cursor.fetchall()
    
    print(f"\n‚úÖ Donn√©es de test g√©n√©r√©es avec succ√®s!")
    print(f"üìä Total des analyses: {total_analyses}")
    print(f"üìà R√©partition par type:")
    for label, count in distribution:
        percentage = (count / total_analyses) * 100
        print(f"   - {label}: {count} ({percentage:.1f}%)")
    
    conn.close()

if __name__ == "__main__":
    generate_test_data()
